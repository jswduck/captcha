{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6314c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed90c0",
   "metadata": {},
   "source": [
    "Build a Captcha Solver \n",
    "=================\n",
    "\n",
    "A website uses Captchas on a form to keep the web-bots away. However, the captchas it generates, are quite similar each time:\n",
    "- the number of characters remains the same each time  \n",
    "- the font and spacing is the same each time  \n",
    "- the background and foreground colors and texture, remain largely the same\n",
    "- there is no skew in the structure of the characters.  \n",
    "- the captcha generator, creates strictly 5-character captchas, and each of the characters is either an upper-case character (A-Z) or a numeral (0-9).\n",
    "\n",
    "\n",
    "A sample of 26 captcha has been provided. We are now to build a captch solver to identify the unseen captcha. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f1bfc",
   "metadata": {},
   "source": [
    "## Solution based on tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89dbf6",
   "metadata": {},
   "source": [
    "Before we can use tesseract, let install tesseract:\n",
    "\n",
    "```shell\n",
    "brew install tesseract\n",
    "\n",
    "brew install tesseract-lang\n",
    "```\n",
    "\n",
    "And in the function <em>inference_with_tesseract</em> in the **Captcha** class, restrict tesseract to only look for uppercase letters and digits. Also set --psm 7 so that tesseract treats individual captcha as a single line\n",
    "\n",
    "```python\n",
    "    tesseract_results = [pytesseract.image_to_string(Image.open(path), config='--psm 7 --oem 1 -l eng -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789').strip()[:5] for path in batch_data['input_file']] # --oem 1 --tessdata-dir /opt/homebrew/share/tessdata\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f42922",
   "metadata": {
    "tag": [
     "tesseract"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 768,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.2\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tesseract OCR for inference\n",
      "Generated text 'EGYK4' saved to ../data/output/pred00.txt\n",
      "Generated text 'GRC35' saved to ../data/output/pred01.txt\n",
      "Generated text '6OSW1' saved to ../data/output/pred02.txt\n",
      "Generated text 'J627C' saved to ../data/output/pred03.txt\n",
      "Generated text 'VLI2C' saved to ../data/output/pred04.txt\n",
      "Generated text 'O1R70' saved to ../data/output/pred05.txt\n",
      "Generated text 'OYTAD' saved to ../data/output/pred06.txt\n",
      "Generated text 'ZRMQU' saved to ../data/output/pred07.txt\n",
      "Generated text 'NDES' saved to ../data/output/pred08.txt\n",
      "Generated text '26553' saved to ../data/output/pred09.txt\n",
      "Generated text 'GZMBA' saved to ../data/output/pred10.txt\n",
      "Generated text 'YMB10' saved to ../data/output/pred100.txt\n",
      "Generated text 'J14D' saved to ../data/output/pred11.txt\n",
      "Generated text 'POSAE' saved to ../data/output/pred12.txt\n",
      "Generated text 'ZD0' saved to ../data/output/pred13.txt\n",
      "Generated text 'WGST7' saved to ../data/output/pred14.txt\n",
      "Generated text 'XKMS2' saved to ../data/output/pred15.txt\n",
      "Generated text '4AD2K' saved to ../data/output/pred16.txt\n",
      "Generated text '20BHQ' saved to ../data/output/pred17.txt\n",
      "Generated text 'OAHOV' saved to ../data/output/pred18.txt\n",
      "Generated text 'SI8VE' saved to ../data/output/pred19.txt\n",
      "Generated text '297ME' saved to ../data/output/pred20.txt\n",
      "Generated text 'L' saved to ../data/output/pred21.txt\n",
      "Generated text 'HCE91' saved to ../data/output/pred22.txt\n",
      "Generated text 'WELXY' saved to ../data/output/pred23.txt\n",
      "Generated text 'UHVFO' saved to ../data/output/pred24.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "from captcha import Captcha\n",
    "import util\n",
    "\n",
    "captcha_solver = Captcha(device, \"../config.yaml\")\n",
    "preds_tesseract = captcha_solver(mode = \"tesseract\", im_path = \"\") # folder with a batch of files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274417b8",
   "metadata": {},
   "source": [
    "### Evaluation of tesseract performance\n",
    "\n",
    "Each sample captcha has a groud truth label already. We will load them and merge with the results and calculate error at both the character level and word level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a51e018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|    |   key | Image File                 | Output File                | Prediction   |\n",
      "+====+=======+============================+============================+==============+\n",
      "|  0 |    00 | ../data/input/input00.jpg  | ../data/output/pred00.txt  | EGYK4        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  1 |    01 | ../data/input/input01.jpg  | ../data/output/pred01.txt  | GRC35        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  2 |    02 | ../data/input/input02.jpg  | ../data/output/pred02.txt  | 6OSW1        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  3 |    03 | ../data/input/input03.jpg  | ../data/output/pred03.txt  | J627C        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  4 |    04 | ../data/input/input04.jpg  | ../data/output/pred04.txt  | VLI2C        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  5 |    05 | ../data/input/input05.jpg  | ../data/output/pred05.txt  | O1R70        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  6 |    06 | ../data/input/input06.jpg  | ../data/output/pred06.txt  | OYTAD        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  7 |    07 | ../data/input/input07.jpg  | ../data/output/pred07.txt  | ZRMQU        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  8 |    08 | ../data/input/input08.jpg  | ../data/output/pred08.txt  | NDES         |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  9 |    09 | ../data/input/input09.jpg  | ../data/output/pred09.txt  | 26553        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 10 |    10 | ../data/input/input10.jpg  | ../data/output/pred10.txt  | GZMBA        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 11 |   100 | ../data/input/input100.jpg | ../data/output/pred100.txt | YMB10        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 12 |    11 | ../data/input/input11.jpg  | ../data/output/pred11.txt  | J14D         |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 13 |    12 | ../data/input/input12.jpg  | ../data/output/pred12.txt  | POSAE        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 14 |    13 | ../data/input/input13.jpg  | ../data/output/pred13.txt  | ZD0          |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 15 |    14 | ../data/input/input14.jpg  | ../data/output/pred14.txt  | WGST7        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 16 |    15 | ../data/input/input15.jpg  | ../data/output/pred15.txt  | XKMS2        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 17 |    16 | ../data/input/input16.jpg  | ../data/output/pred16.txt  | 4AD2K        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 18 |    17 | ../data/input/input17.jpg  | ../data/output/pred17.txt  | 20BHQ        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 19 |    18 | ../data/input/input18.jpg  | ../data/output/pred18.txt  | OAHOV        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 20 |    19 | ../data/input/input19.jpg  | ../data/output/pred19.txt  | SI8VE        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 21 |    20 | ../data/input/input20.jpg  | ../data/output/pred20.txt  | 297ME        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 22 |    21 | ../data/input/input21.jpg  | ../data/output/pred21.txt  | L            |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 23 |    22 | ../data/input/input22.jpg  | ../data/output/pred22.txt  | HCE91        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 24 |    23 | ../data/input/input23.jpg  | ../data/output/pred23.txt  | WELXY        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 25 |    24 | ../data/input/input24.jpg  | ../data/output/pred24.txt  | UHVFO        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# let us look at the predicted text first\n",
    "from tabulate import tabulate\n",
    "\n",
    "headers = ['key', 'Image File', 'Output File', 'Prediction']\n",
    "print(tabulate(preds_tesseract, headers=headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76fe3e",
   "metadata": {},
   "source": [
    "And now load the existing labels. They are in output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0306872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|    |   key | Image File                 | Output File                | Prediction   | GT Label   | Correct   |\n",
      "+====+=======+============================+============================+==============+============+===========+\n",
      "|  0 |    00 | ../data/input/input00.jpg  | ../data/output/pred00.txt  | EGYK4        | EGYK4      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  1 |    01 | ../data/input/input01.jpg  | ../data/output/pred01.txt  | GRC35        | GRC35      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  2 |    02 | ../data/input/input02.jpg  | ../data/output/pred02.txt  | 6OSW1        | 6O5W1      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  3 |    03 | ../data/input/input03.jpg  | ../data/output/pred03.txt  | J627C        | J627C      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  4 |    04 | ../data/input/input04.jpg  | ../data/output/pred04.txt  | VLI2C        | VLI2C      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  5 |    05 | ../data/input/input05.jpg  | ../data/output/pred05.txt  | O1R70        | O1R7Q      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  6 |    06 | ../data/input/input06.jpg  | ../data/output/pred06.txt  | OYTAD        | OYTAD      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  7 |    07 | ../data/input/input07.jpg  | ../data/output/pred07.txt  | ZRMQU        | ZRMQU      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  8 |    08 | ../data/input/input08.jpg  | ../data/output/pred08.txt  | NDES         | N9DQS      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  9 |    09 | ../data/input/input09.jpg  | ../data/output/pred09.txt  | 26553        | ZGJS3      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 10 |    10 | ../data/input/input10.jpg  | ../data/output/pred10.txt  | GZMBA        | GZMBA      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 11 |   100 | ../data/input/input100.jpg | ../data/output/pred100.txt | YMB10        | YMB1Q      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 12 |    11 | ../data/input/input11.jpg  | ../data/output/pred11.txt  | J14D         | J14DM      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 13 |    12 | ../data/input/input12.jpg  | ../data/output/pred12.txt  | POSAE        | PQ9AE      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 14 |    13 | ../data/input/input13.jpg  | ../data/output/pred13.txt  | ZD0          | VWZDO      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 15 |    14 | ../data/input/input14.jpg  | ../data/output/pred14.txt  | WGST7        | WGST7      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 16 |    15 | ../data/input/input15.jpg  | ../data/output/pred15.txt  | XKMS2        | XKMS2      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 17 |    16 | ../data/input/input16.jpg  | ../data/output/pred16.txt  | 4AD2K        | 1D2KB      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 18 |    17 | ../data/input/input17.jpg  | ../data/output/pred17.txt  | 20BHQ        | 20BHQ      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 19 |    18 | ../data/input/input18.jpg  | ../data/output/pred18.txt  | OAHOV        | OAH0V      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 20 |    19 | ../data/input/input19.jpg  | ../data/output/pred19.txt  | SI8VE        | 5I8VE      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 21 |    20 | ../data/input/input20.jpg  | ../data/output/pred20.txt  | 297ME        | Z97ME      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 22 |    21 | ../data/input/input21.jpg  | ../data/output/pred21.txt  | L            | CL69V      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 23 |    22 | ../data/input/input22.jpg  | ../data/output/pred22.txt  | HCE91        | HCE91      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 24 |    23 | ../data/input/input23.jpg  | ../data/output/pred23.txt  | WELXY        | WELXV      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 25 |    24 | ../data/input/input24.jpg  | ../data/output/pred24.txt  | UHVFO        | UHVFO      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "preds_tesseract_with_labels = captcha_solver.add_gt_labels(preds_tesseract)\n",
    "\n",
    "headers = ['key','Image File', 'Output File', 'Prediction'  , 'GT Label', 'Correct']\n",
    "print(tabulate(preds_tesseract_with_labels, headers=headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15966a",
   "metadata": {},
   "source": [
    "Let's now analyze the error at both character level and word level, i.e., <em>CER</em> and <em>WER</em>.\n",
    "\n",
    "Load the library from HF first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf90c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load the metric\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "wer_metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196e80c",
   "metadata": {},
   "source": [
    "#### CER and WER calculation\n",
    "\n",
    "Now calculate the CER and WER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4c088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Character Error Rate (CER): 20.00%\n",
      "Overall Word Error Rate (WER): 53.85%\n",
      "\n",
      "Detailed Analysis:\n",
      "============================================================\n",
      "\n",
      "Sample 02:\n",
      "Expected: 6O5W1\n",
      "Predicted: 6OSW1\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 2: Expected '5', Got 'S'\n",
      "Image file: ../data/input/input02.jpg\n",
      "\n",
      "Sample 05:\n",
      "Expected: O1R7Q\n",
      "Predicted: O1R70\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 4: Expected 'Q', Got '0'\n",
      "Image file: ../data/input/input05.jpg\n",
      "\n",
      "Sample 08:\n",
      "Expected: N9DQS\n",
      "Predicted: NDES\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected '9', Got 'D'\n",
      "Position 2: Expected 'D', Got 'E'\n",
      "Position 3: Expected 'Q', Got 'S'\n",
      "Length mismatch: Expected 5, Got 4\n",
      "Image file: ../data/input/input08.jpg\n",
      "\n",
      "Sample 09:\n",
      "Expected: ZGJS3\n",
      "Predicted: 26553\n",
      "CER: 80.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'Z', Got '2'\n",
      "Position 1: Expected 'G', Got '6'\n",
      "Position 2: Expected 'J', Got '5'\n",
      "Position 3: Expected 'S', Got '5'\n",
      "Image file: ../data/input/input09.jpg\n",
      "\n",
      "Sample 100:\n",
      "Expected: YMB1Q\n",
      "Predicted: YMB10\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 4: Expected 'Q', Got '0'\n",
      "Image file: ../data/input/input100.jpg\n",
      "\n",
      "Sample 11:\n",
      "Expected: J14DM\n",
      "Predicted: J14D\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Length mismatch: Expected 5, Got 4\n",
      "Image file: ../data/input/input11.jpg\n",
      "\n",
      "Sample 12:\n",
      "Expected: PQ9AE\n",
      "Predicted: POSAE\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'Q', Got 'O'\n",
      "Position 2: Expected '9', Got 'S'\n",
      "Image file: ../data/input/input12.jpg\n",
      "\n",
      "Sample 13:\n",
      "Expected: VWZDO\n",
      "Predicted: ZD0\n",
      "CER: 60.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'V', Got 'Z'\n",
      "Position 1: Expected 'W', Got 'D'\n",
      "Position 2: Expected 'Z', Got '0'\n",
      "Length mismatch: Expected 5, Got 3\n",
      "Image file: ../data/input/input13.jpg\n",
      "\n",
      "Sample 16:\n",
      "Expected: 1D2KB\n",
      "Predicted: 4AD2K\n",
      "CER: 60.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected '1', Got '4'\n",
      "Position 1: Expected 'D', Got 'A'\n",
      "Position 2: Expected '2', Got 'D'\n",
      "Position 3: Expected 'K', Got '2'\n",
      "Position 4: Expected 'B', Got 'K'\n",
      "Image file: ../data/input/input16.jpg\n",
      "\n",
      "Sample 18:\n",
      "Expected: OAH0V\n",
      "Predicted: OAHOV\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected '0', Got 'O'\n",
      "Image file: ../data/input/input18.jpg\n",
      "\n",
      "Sample 19:\n",
      "Expected: 5I8VE\n",
      "Predicted: SI8VE\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected '5', Got 'S'\n",
      "Image file: ../data/input/input19.jpg\n",
      "\n",
      "Sample 20:\n",
      "Expected: Z97ME\n",
      "Predicted: 297ME\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'Z', Got '2'\n",
      "Image file: ../data/input/input20.jpg\n",
      "\n",
      "Sample 21:\n",
      "Expected: CL69V\n",
      "Predicted: L\n",
      "CER: 80.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'C', Got 'L'\n",
      "Length mismatch: Expected 5, Got 1\n",
      "Image file: ../data/input/input21.jpg\n",
      "\n",
      "Sample 23:\n",
      "Expected: WELXV\n",
      "Predicted: WELXY\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 4: Expected 'V', Got 'Y'\n",
      "Image file: ../data/input/input23.jpg\n"
     ]
    }
   ],
   "source": [
    "# Calculate CER & WER for all captcha samples\n",
    "predictions = preds_tesseract_with_labels['prediction'].tolist()\n",
    "references = preds_tesseract_with_labels['ground_truth'].tolist()\n",
    "\n",
    "# Compute CER & WER\n",
    "cer_result = cer_metric.compute(predictions=predictions, references=references)\n",
    "wer_result = wer_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overall Character Error Rate (CER): {cer_result:.2%}\")\n",
    "print(f\"Overall Word Error Rate (WER): {wer_result:.2%}\")\n",
    "\n",
    "# Detailed analysis per sample\n",
    "print(\"\\nDetailed Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "# Iterate through DataFrame rows for detailed analysis\n",
    "for _, row in preds_tesseract_with_labels.iterrows():\n",
    "    pred = row['prediction']\n",
    "    ref = row['ground_truth']\n",
    "    key = row['key']\n",
    "    \n",
    "    # Calculate metrics for this sample\n",
    "    sample_cer = cer_metric.compute(predictions=[pred], references=[ref])\n",
    "    sample_wer = wer_metric.compute(predictions=[pred], references=[ref])\n",
    "    \n",
    "    # Only show samples with errors\n",
    "    if sample_cer > 0 or sample_wer > 0:\n",
    "        print(f\"\\nSample {key}:\")\n",
    "        print(f\"Expected: {ref}\")\n",
    "        print(f\"Predicted: {pred}\")\n",
    "        print(f\"CER: {sample_cer:.2%}\")\n",
    "        print(f\"WER: {sample_wer:.2%}\")\n",
    "        \n",
    "        # Show character-by-character comparison\n",
    "        print(\"Character differences:\")\n",
    "        for j, (c1, c2) in enumerate(zip(ref, pred)):\n",
    "            if c1 != c2:\n",
    "                print(f\"Position {j}: Expected '{c1}', Got '{c2}'\")\n",
    "        \n",
    "        # Handle different lengths\n",
    "        if len(ref) != len(pred):\n",
    "            print(f\"Length mismatch: Expected {len(ref)}, Got {len(pred)}\")\n",
    "            \n",
    "        # Show image file for reference\n",
    "        print(f\"Image file: {row['input_file']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42120143",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "It can be seen that tesseract (LSTM engine, with English) does not achieve very good performance on the sample set. It achieves a CER of 20%, and a WER of 53.85%. For some captcha, it identifies less than 5 characters. \n",
    "\n",
    "And with tesseract, preprocessing (cropping the text and remove the background) does not help in improving the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ec17a",
   "metadata": {},
   "source": [
    "## Solution based on TrOCR, without preprocessing\n",
    "\n",
    "We will use pre-trained TrOCR from Microsoft for this task. \n",
    "\n",
    "TrOCR has a family of pre-trained models, including **trocr-small-printed**, **trocr-base-printed**, **trocr-base-handwritten**, etc. Since we are dealing with clear and consistent texts, we will choose modle fine tuned with printed text, like **trocr-base-printed**. \n",
    "\n",
    "We also need to balance inference speed and accuracy. We will go with **trocr-base-printed** first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fb6d2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 768,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.2\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from captcha import Captcha\n",
    "import util\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "captcha_solver = Captcha(device, \"../config.yaml\") # run again to reload the config.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea424518",
   "metadata": {},
   "source": [
    "Let's do it without pre-processing of the captha images first. This is a switch that can be set in the config.yaml. In the same config file, we can also change the pretrained model.\n",
    "\n",
    "```yaml\n",
    "model: \n",
    "    preprocessing: false\n",
    "    pretrained_path: \"microsoft/trocr-base-printed\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c802f61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TrOCR for inference\n",
      "Preprocessing turned off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsweng/.pyenv/versions/3.10.13/envs/captcha/lib/python3.10/site-packages/transformers/generation/utils.py:1667: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text 'EGYK4' saved to ../data/output/pred00.txt\n",
      "Generated text 'GRC35' saved to ../data/output/pred01.txt\n",
      "Generated text '605W1' saved to ../data/output/pred02.txt\n",
      "Generated text 'J627C' saved to ../data/output/pred03.txt\n",
      "Generated text 'VL12C' saved to ../data/output/pred04.txt\n",
      "Generated text '01R70' saved to ../data/output/pred05.txt\n",
      "Generated text 'OYTAD' saved to ../data/output/pred06.txt\n",
      "Generated text 'ZRMOU' saved to ../data/output/pred07.txt\n",
      "Generated text 'N9DOS' saved to ../data/output/pred08.txt\n",
      "Generated text '2GJ53' saved to ../data/output/pred09.txt\n",
      "Generated text 'GZMBA' saved to ../data/output/pred10.txt\n",
      "Generated text 'YMB1Q' saved to ../data/output/pred100.txt\n",
      "Generated text 'J14DM' saved to ../data/output/pred11.txt\n",
      "Generated text 'POSAE' saved to ../data/output/pred12.txt\n",
      "Generated text 'VWZDO' saved to ../data/output/pred13.txt\n",
      "Generated text 'WGSTZ' saved to ../data/output/pred14.txt\n",
      "Generated text 'XKMS2' saved to ../data/output/pred15.txt\n",
      "Generated text '102KB' saved to ../data/output/pred16.txt\n",
      "Generated text '20BHQ' saved to ../data/output/pred17.txt\n",
      "Generated text 'DAHOV' saved to ../data/output/pred18.txt\n",
      "Generated text '518VE' saved to ../data/output/pred19.txt\n",
      "Generated text '29ZME' saved to ../data/output/pred20.txt\n",
      "Generated text 'CL69V' saved to ../data/output/pred21.txt\n",
      "Generated text 'HOE91' saved to ../data/output/pred22.txt\n",
      "Generated text 'WELXV' saved to ../data/output/pred23.txt\n",
      "Generated text 'UHVFO' saved to ../data/output/pred24.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# captcha_solver(\"../data/input/input100.jpg\",\"../data/output/100.txt\") # individual file\n",
    "\n",
    "\n",
    "preds_trocr = captcha_solver(mode = \"TrOCR\", im_path = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9668e",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Like what we did with tesseract, we will evaluate performance with both CER and WER. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b516b99",
   "metadata": {},
   "source": [
    "Let us look at the predictions first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e1621b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load the metric\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "wer_metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ace4bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|    |   key | Image File                 | Output File                | Prediction   |\n",
      "+====+=======+============================+============================+==============+\n",
      "|  0 |    00 | ../data/input/input00.jpg  | ../data/output/pred00.txt  | EGYK4        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  1 |    01 | ../data/input/input01.jpg  | ../data/output/pred01.txt  | GRC35        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  2 |    02 | ../data/input/input02.jpg  | ../data/output/pred02.txt  | 605W1        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  3 |    03 | ../data/input/input03.jpg  | ../data/output/pred03.txt  | J627C        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  4 |    04 | ../data/input/input04.jpg  | ../data/output/pred04.txt  | VL12C        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  5 |    05 | ../data/input/input05.jpg  | ../data/output/pred05.txt  | 01R70        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  6 |    06 | ../data/input/input06.jpg  | ../data/output/pred06.txt  | OYTAD        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  7 |    07 | ../data/input/input07.jpg  | ../data/output/pred07.txt  | ZRMOU        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  8 |    08 | ../data/input/input08.jpg  | ../data/output/pred08.txt  | N9DOS        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "|  9 |    09 | ../data/input/input09.jpg  | ../data/output/pred09.txt  | 2GJ53        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 10 |    10 | ../data/input/input10.jpg  | ../data/output/pred10.txt  | GZMBA        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 11 |   100 | ../data/input/input100.jpg | ../data/output/pred100.txt | YMB1Q        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 12 |    11 | ../data/input/input11.jpg  | ../data/output/pred11.txt  | J14DM        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 13 |    12 | ../data/input/input12.jpg  | ../data/output/pred12.txt  | POSAE        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 14 |    13 | ../data/input/input13.jpg  | ../data/output/pred13.txt  | VWZDO        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 15 |    14 | ../data/input/input14.jpg  | ../data/output/pred14.txt  | WGSTZ        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 16 |    15 | ../data/input/input15.jpg  | ../data/output/pred15.txt  | XKMS2        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 17 |    16 | ../data/input/input16.jpg  | ../data/output/pred16.txt  | 102KB        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 18 |    17 | ../data/input/input17.jpg  | ../data/output/pred17.txt  | 20BHQ        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 19 |    18 | ../data/input/input18.jpg  | ../data/output/pred18.txt  | DAHOV        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 20 |    19 | ../data/input/input19.jpg  | ../data/output/pred19.txt  | 518VE        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 21 |    20 | ../data/input/input20.jpg  | ../data/output/pred20.txt  | 29ZME        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 22 |    21 | ../data/input/input21.jpg  | ../data/output/pred21.txt  | CL69V        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 23 |    22 | ../data/input/input22.jpg  | ../data/output/pred22.txt  | HOE91        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 24 |    23 | ../data/input/input23.jpg  | ../data/output/pred23.txt  | WELXV        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n",
      "| 25 |    24 | ../data/input/input24.jpg  | ../data/output/pred24.txt  | UHVFO        |\n",
      "+----+-------+----------------------------+----------------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# let us look at the predicted text first\n",
    "from tabulate import tabulate\n",
    "\n",
    "headers = ['key', 'Image File', 'Output File', 'Prediction']\n",
    "print(tabulate(preds_trocr, headers=headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a27237ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|    |   key | Image File                 | Output File                | Prediction   | GT Label   | Correct   |\n",
      "+====+=======+============================+============================+==============+============+===========+\n",
      "|  0 |    00 | ../data/input/input00.jpg  | ../data/output/pred00.txt  | EGYK4        | EGYK4      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  1 |    01 | ../data/input/input01.jpg  | ../data/output/pred01.txt  | GRC35        | GRC35      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  2 |    02 | ../data/input/input02.jpg  | ../data/output/pred02.txt  | 605W1        | 6O5W1      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  3 |    03 | ../data/input/input03.jpg  | ../data/output/pred03.txt  | J627C        | J627C      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  4 |    04 | ../data/input/input04.jpg  | ../data/output/pred04.txt  | VL12C        | VLI2C      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  5 |    05 | ../data/input/input05.jpg  | ../data/output/pred05.txt  | 01R70        | O1R7Q      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  6 |    06 | ../data/input/input06.jpg  | ../data/output/pred06.txt  | OYTAD        | OYTAD      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  7 |    07 | ../data/input/input07.jpg  | ../data/output/pred07.txt  | ZRMOU        | ZRMQU      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  8 |    08 | ../data/input/input08.jpg  | ../data/output/pred08.txt  | N9DOS        | N9DQS      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  9 |    09 | ../data/input/input09.jpg  | ../data/output/pred09.txt  | 2GJ53        | ZGJS3      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 10 |    10 | ../data/input/input10.jpg  | ../data/output/pred10.txt  | GZMBA        | GZMBA      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 11 |   100 | ../data/input/input100.jpg | ../data/output/pred100.txt | YMB1Q        | YMB1Q      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 12 |    11 | ../data/input/input11.jpg  | ../data/output/pred11.txt  | J14DM        | J14DM      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 13 |    12 | ../data/input/input12.jpg  | ../data/output/pred12.txt  | POSAE        | PQ9AE      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 14 |    13 | ../data/input/input13.jpg  | ../data/output/pred13.txt  | VWZDO        | VWZDO      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 15 |    14 | ../data/input/input14.jpg  | ../data/output/pred14.txt  | WGSTZ        | WGST7      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 16 |    15 | ../data/input/input15.jpg  | ../data/output/pred15.txt  | XKMS2        | XKMS2      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 17 |    16 | ../data/input/input16.jpg  | ../data/output/pred16.txt  | 102KB        | 1D2KB      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 18 |    17 | ../data/input/input17.jpg  | ../data/output/pred17.txt  | 20BHQ        | 20BHQ      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 19 |    18 | ../data/input/input18.jpg  | ../data/output/pred18.txt  | DAHOV        | OAH0V      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 20 |    19 | ../data/input/input19.jpg  | ../data/output/pred19.txt  | 518VE        | 5I8VE      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 21 |    20 | ../data/input/input20.jpg  | ../data/output/pred20.txt  | 29ZME        | Z97ME      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 22 |    21 | ../data/input/input21.jpg  | ../data/output/pred21.txt  | CL69V        | CL69V      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 23 |    22 | ../data/input/input22.jpg  | ../data/output/pred22.txt  | HOE91        | HCE91      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 24 |    23 | ../data/input/input23.jpg  | ../data/output/pred23.txt  | WELXV        | WELXV      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 25 |    24 | ../data/input/input24.jpg  | ../data/output/pred24.txt  | UHVFO        | UHVFO      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "preds_trocr_with_labels = captcha_solver.add_gt_labels(preds_trocr)\n",
    "\n",
    "headers = ['key','Image File', 'Output File', 'Prediction'  , 'GT Label', 'Correct']\n",
    "print(tabulate(preds_trocr_with_labels, headers=headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba27192",
   "metadata": {},
   "source": [
    "#### CER and WER calculation\n",
    "\n",
    "Let's calculate with the TrOCR inference results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc59dba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Character Error Rate (CER): 13.85%\n",
      "Overall Word Error Rate (WER): 50.00%\n",
      "\n",
      "Detailed Analysis:\n",
      "============================================================\n",
      "\n",
      "Sample 02:\n",
      "Expected: 6O5W1\n",
      "Predicted: 605W1\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'O', Got '0'\n",
      "Image file: ../data/input/input02.jpg\n",
      "\n",
      "Sample 04:\n",
      "Expected: VLI2C\n",
      "Predicted: VL12C\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 2: Expected 'I', Got '1'\n",
      "Image file: ../data/input/input04.jpg\n",
      "\n",
      "Sample 05:\n",
      "Expected: O1R7Q\n",
      "Predicted: 01R70\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'O', Got '0'\n",
      "Position 4: Expected 'Q', Got '0'\n",
      "Image file: ../data/input/input05.jpg\n",
      "\n",
      "Sample 07:\n",
      "Expected: ZRMQU\n",
      "Predicted: ZRMOU\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected 'Q', Got 'O'\n",
      "Image file: ../data/input/input07.jpg\n",
      "\n",
      "Sample 08:\n",
      "Expected: N9DQS\n",
      "Predicted: N9DOS\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected 'Q', Got 'O'\n",
      "Image file: ../data/input/input08.jpg\n",
      "\n",
      "Sample 09:\n",
      "Expected: ZGJS3\n",
      "Predicted: 2GJ53\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'Z', Got '2'\n",
      "Position 3: Expected 'S', Got '5'\n",
      "Image file: ../data/input/input09.jpg\n",
      "\n",
      "Sample 12:\n",
      "Expected: PQ9AE\n",
      "Predicted: POSAE\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'Q', Got 'O'\n",
      "Position 2: Expected '9', Got 'S'\n",
      "Image file: ../data/input/input12.jpg\n",
      "\n",
      "Sample 14:\n",
      "Expected: WGST7\n",
      "Predicted: WGSTZ\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 4: Expected '7', Got 'Z'\n",
      "Image file: ../data/input/input14.jpg\n",
      "\n",
      "Sample 16:\n",
      "Expected: 1D2KB\n",
      "Predicted: 102KB\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'D', Got '0'\n",
      "Image file: ../data/input/input16.jpg\n",
      "\n",
      "Sample 18:\n",
      "Expected: OAH0V\n",
      "Predicted: DAHOV\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'O', Got 'D'\n",
      "Position 3: Expected '0', Got 'O'\n",
      "Image file: ../data/input/input18.jpg\n",
      "\n",
      "Sample 19:\n",
      "Expected: 5I8VE\n",
      "Predicted: 518VE\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'I', Got '1'\n",
      "Image file: ../data/input/input19.jpg\n",
      "\n",
      "Sample 20:\n",
      "Expected: Z97ME\n",
      "Predicted: 29ZME\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'Z', Got '2'\n",
      "Position 2: Expected '7', Got 'Z'\n",
      "Image file: ../data/input/input20.jpg\n",
      "\n",
      "Sample 22:\n",
      "Expected: HCE91\n",
      "Predicted: HOE91\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'C', Got 'O'\n",
      "Image file: ../data/input/input22.jpg\n"
     ]
    }
   ],
   "source": [
    "# Calculate CER & WER for all captcha samples\n",
    "predictions = preds_trocr_with_labels['prediction'].tolist()\n",
    "references = preds_trocr_with_labels['ground_truth'].tolist()\n",
    "\n",
    "# Compute CER & WER\n",
    "cer_result = cer_metric.compute(predictions=predictions, references=references)\n",
    "wer_result = wer_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overall Character Error Rate (CER): {cer_result:.2%}\")\n",
    "print(f\"Overall Word Error Rate (WER): {wer_result:.2%}\")\n",
    "\n",
    "# Detailed analysis per sample\n",
    "print(\"\\nDetailed Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "# Iterate through DataFrame rows for detailed analysis\n",
    "for _, row in preds_trocr_with_labels.iterrows():\n",
    "    pred = row['prediction']\n",
    "    ref = row['ground_truth']\n",
    "    key = row['key']\n",
    "    \n",
    "    # Calculate metrics for this sample\n",
    "    sample_cer = cer_metric.compute(predictions=[pred], references=[ref])\n",
    "    sample_wer = wer_metric.compute(predictions=[pred], references=[ref])\n",
    "    \n",
    "    # Only show samples with errors\n",
    "    if sample_cer > 0 or sample_wer > 0:\n",
    "        print(f\"\\nSample {key}:\")\n",
    "        print(f\"Expected: {ref}\")\n",
    "        print(f\"Predicted: {pred}\")\n",
    "        print(f\"CER: {sample_cer:.2%}\")\n",
    "        print(f\"WER: {sample_wer:.2%}\")\n",
    "        \n",
    "        # Show character-by-character comparison\n",
    "        print(\"Character differences:\")\n",
    "        for j, (c1, c2) in enumerate(zip(ref, pred)):\n",
    "            if c1 != c2:\n",
    "                print(f\"Position {j}: Expected '{c1}', Got '{c2}'\")\n",
    "        \n",
    "        # Handle different lengths\n",
    "        if len(ref) != len(pred):\n",
    "            print(f\"Length mismatch: Expected {len(ref)}, Got {len(pred)}\")\n",
    "            \n",
    "        # Show image file for reference\n",
    "        print(f\"Image file: {row['input_file']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8152e622",
   "metadata": {},
   "source": [
    "CER is now 13.85%, and WER is 50%; while the same for tesseract are 20% and 53.85% respectively. \n",
    "\n",
    "There is an improvement, though not much. Let's see whether preprocessing can improve further. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b9fc0d",
   "metadata": {},
   "source": [
    "## Solution with TrOCR, with image pre-processing\n",
    "\n",
    "Let's see whether we can improve the performance with additional pre-processing steps on the captchas. \n",
    "\n",
    "Since the number of characters remains the same in each captcha, the font and spacing is the same each time, and the background and foreground colors and texture also remain largely the same, two preprocessing steps could help to enhance the images:\n",
    "\n",
    "- removing the background by setting threshold\n",
    "- cropping the image to bound the text only.\n",
    "\n",
    "**config.yaml** has a switch <em>preprocessing</em>. Setting it to true would turn on pre-processing. **REMEMBER** to turn it on before continue.\n",
    "\n",
    "```yaml\n",
    "model: \n",
    "    preprocessing: true\n",
    "    pretrained_path: \"microsoft/trocr-base-printed\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bab85b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 768,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.2\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TrOCR for inference\n",
      "Preprocessing turned on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsweng/.pyenv/versions/3.10.13/envs/captcha/lib/python3.10/site-packages/transformers/generation/utils.py:1667: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text 'EGYK4' saved to ../data/output/pred00.txt\n",
      "Generated text 'GRC35' saved to ../data/output/pred01.txt\n",
      "Generated text '605W1' saved to ../data/output/pred02.txt\n",
      "Generated text 'J627C' saved to ../data/output/pred03.txt\n",
      "Generated text 'VLI2C' saved to ../data/output/pred04.txt\n",
      "Generated text '01RZQ' saved to ../data/output/pred05.txt\n",
      "Generated text 'OYTAD' saved to ../data/output/pred06.txt\n",
      "Generated text 'ZRMQU' saved to ../data/output/pred07.txt\n",
      "Generated text 'N9DQS' saved to ../data/output/pred08.txt\n",
      "Generated text 'ZGJ53' saved to ../data/output/pred09.txt\n",
      "Generated text 'GZMBA' saved to ../data/output/pred10.txt\n",
      "Generated text 'YMB1Q' saved to ../data/output/pred100.txt\n",
      "Generated text 'J14DM' saved to ../data/output/pred11.txt\n",
      "Generated text 'PQ9AE' saved to ../data/output/pred12.txt\n",
      "Generated text 'VWZDO' saved to ../data/output/pred13.txt\n",
      "Generated text 'WGST7' saved to ../data/output/pred14.txt\n",
      "Generated text 'XKMS2' saved to ../data/output/pred15.txt\n",
      "Generated text '1D2KB' saved to ../data/output/pred16.txt\n",
      "Generated text '20BHQ' saved to ../data/output/pred17.txt\n",
      "Generated text 'OAHOV' saved to ../data/output/pred18.txt\n",
      "Generated text '5I8VE' saved to ../data/output/pred19.txt\n",
      "Generated text 'Z97ME' saved to ../data/output/pred20.txt\n",
      "Generated text 'CL69V' saved to ../data/output/pred21.txt\n",
      "Generated text 'HCE91' saved to ../data/output/pred22.txt\n",
      "Generated text 'WELXV' saved to ../data/output/pred23.txt\n",
      "Generated text 'UHVFO' saved to ../data/output/pred24.txt\n"
     ]
    }
   ],
   "source": [
    "captcha_solver = Captcha(device, \"../config.yaml\") # run again to reload the config.yaml\n",
    "\n",
    "preds_trocr_with_preprocessing = captcha_solver(mode = \"TrOCR\", im_path = \"\")  \n",
    "\n",
    "preds_trocr_with_preprocessing_with_labels = captcha_solver.add_gt_labels(preds_trocr_with_preprocessing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645134c",
   "metadata": {},
   "source": [
    "Let's look at the effect of preprocessing before we further proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae7c67b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WGST7\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "\n",
    "index = 15\n",
    "image_path = preds_trocr_with_preprocessing_with_labels['input_file'][index]  # Use the existing image for testing\n",
    "\n",
    "\n",
    "# Show original, and preprocessed image\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Original image\n",
    "#original = Image.open(image_path)\n",
    "ax1.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "ax1.set_title('Original Image')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Preprocessed image\n",
    "preprocessed = util.preprocess_captcha(image_path)\n",
    "ax2.imshow(preprocessed)\n",
    "ax2.set_title('Preprocessed Image')\n",
    "ax2.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print the label\n",
    "print(f\"{preds_trocr_with_preprocessing_with_labels['ground_truth'][index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260139fa",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "The prediction from TrOCR after preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bfbae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|    |   key | Image File                 | Output File                | Prediction   | GT Label   | Correct   |\n",
      "+====+=======+============================+============================+==============+============+===========+\n",
      "|  0 |    00 | ../data/input/input00.jpg  | ../data/output/pred00.txt  | EGYK4        | EGYK4      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  1 |    01 | ../data/input/input01.jpg  | ../data/output/pred01.txt  | GRC35        | GRC35      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  2 |    02 | ../data/input/input02.jpg  | ../data/output/pred02.txt  | 605W1        | 6O5W1      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  3 |    03 | ../data/input/input03.jpg  | ../data/output/pred03.txt  | J627C        | J627C      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  4 |    04 | ../data/input/input04.jpg  | ../data/output/pred04.txt  | VLI2C        | VLI2C      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  5 |    05 | ../data/input/input05.jpg  | ../data/output/pred05.txt  | 01RZQ        | O1R7Q      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  6 |    06 | ../data/input/input06.jpg  | ../data/output/pred06.txt  | OYTAD        | OYTAD      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  7 |    07 | ../data/input/input07.jpg  | ../data/output/pred07.txt  | ZRMQU        | ZRMQU      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  8 |    08 | ../data/input/input08.jpg  | ../data/output/pred08.txt  | N9DQS        | N9DQS      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "|  9 |    09 | ../data/input/input09.jpg  | ../data/output/pred09.txt  | ZGJ53        | ZGJS3      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 10 |    10 | ../data/input/input10.jpg  | ../data/output/pred10.txt  | GZMBA        | GZMBA      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 11 |   100 | ../data/input/input100.jpg | ../data/output/pred100.txt | YMB1Q        | YMB1Q      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 12 |    11 | ../data/input/input11.jpg  | ../data/output/pred11.txt  | J14DM        | J14DM      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 13 |    12 | ../data/input/input12.jpg  | ../data/output/pred12.txt  | PQ9AE        | PQ9AE      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 14 |    13 | ../data/input/input13.jpg  | ../data/output/pred13.txt  | VWZDO        | VWZDO      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 15 |    14 | ../data/input/input14.jpg  | ../data/output/pred14.txt  | WGST7        | WGST7      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 16 |    15 | ../data/input/input15.jpg  | ../data/output/pred15.txt  | XKMS2        | XKMS2      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 17 |    16 | ../data/input/input16.jpg  | ../data/output/pred16.txt  | 1D2KB        | 1D2KB      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 18 |    17 | ../data/input/input17.jpg  | ../data/output/pred17.txt  | 20BHQ        | 20BHQ      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 19 |    18 | ../data/input/input18.jpg  | ../data/output/pred18.txt  | OAHOV        | OAH0V      | False     |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 20 |    19 | ../data/input/input19.jpg  | ../data/output/pred19.txt  | 5I8VE        | 5I8VE      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 21 |    20 | ../data/input/input20.jpg  | ../data/output/pred20.txt  | Z97ME        | Z97ME      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 22 |    21 | ../data/input/input21.jpg  | ../data/output/pred21.txt  | CL69V        | CL69V      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 23 |    22 | ../data/input/input22.jpg  | ../data/output/pred22.txt  | HCE91        | HCE91      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 24 |    23 | ../data/input/input23.jpg  | ../data/output/pred23.txt  | WELXV        | WELXV      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n",
      "| 25 |    24 | ../data/input/input24.jpg  | ../data/output/pred24.txt  | UHVFO        | UHVFO      | True      |\n",
      "+----+-------+----------------------------+----------------------------+--------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "headers = ['key','Image File', 'Output File', 'Prediction'  , 'GT Label', 'Correct']\n",
    "print(tabulate(preds_trocr_with_preprocessing_with_labels, headers=headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a3b32",
   "metadata": {},
   "source": [
    "#### CER and WER calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f269f1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Character Error Rate (CER): 3.85%\n",
      "Overall Word Error Rate (WER): 15.38%\n",
      "\n",
      "Detailed Analysis:\n",
      "============================================================\n",
      "\n",
      "Sample 02:\n",
      "Expected: 6O5W1\n",
      "Predicted: 605W1\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'O', Got '0'\n",
      "Image file: ../data/input/input02.jpg\n",
      "\n",
      "Sample 05:\n",
      "Expected: O1R7Q\n",
      "Predicted: 01RZQ\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'O', Got '0'\n",
      "Position 3: Expected '7', Got 'Z'\n",
      "Image file: ../data/input/input05.jpg\n",
      "\n",
      "Sample 09:\n",
      "Expected: ZGJS3\n",
      "Predicted: ZGJ53\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected 'S', Got '5'\n",
      "Image file: ../data/input/input09.jpg\n",
      "\n",
      "Sample 18:\n",
      "Expected: OAH0V\n",
      "Predicted: OAHOV\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected '0', Got 'O'\n",
      "Image file: ../data/input/input18.jpg\n"
     ]
    }
   ],
   "source": [
    "predictions = preds_trocr_with_preprocessing_with_labels['prediction'].tolist()\n",
    "references = preds_trocr_with_preprocessing_with_labels['ground_truth'].tolist()\n",
    "\n",
    "# Compute CER & WER\n",
    "cer_result = cer_metric.compute(predictions=predictions, references=references)\n",
    "wer_result = wer_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overall Character Error Rate (CER): {cer_result:.2%}\")\n",
    "print(f\"Overall Word Error Rate (WER): {wer_result:.2%}\")\n",
    "\n",
    "# Detailed analysis per sample\n",
    "print(\"\\nDetailed Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "# Iterate through DataFrame rows for detailed analysis\n",
    "for _, row in preds_trocr_with_preprocessing_with_labels.iterrows():\n",
    "    pred = row['prediction']\n",
    "    ref = row['ground_truth']\n",
    "    key = row['key']\n",
    "    \n",
    "    # Calculate metrics for this sample\n",
    "    sample_cer = cer_metric.compute(predictions=[pred], references=[ref])\n",
    "    sample_wer = wer_metric.compute(predictions=[pred], references=[ref])\n",
    "    \n",
    "    # Only show samples with errors\n",
    "    if sample_cer > 0 or sample_wer > 0:\n",
    "        print(f\"\\nSample {key}:\")\n",
    "        print(f\"Expected: {ref}\")\n",
    "        print(f\"Predicted: {pred}\")\n",
    "        print(f\"CER: {sample_cer:.2%}\")\n",
    "        print(f\"WER: {sample_wer:.2%}\")\n",
    "        \n",
    "        # Show character-by-character comparison\n",
    "        print(\"Character differences:\")\n",
    "        for j, (c1, c2) in enumerate(zip(ref, pred)):\n",
    "            if c1 != c2:\n",
    "                print(f\"Position {j}: Expected '{c1}', Got '{c2}'\")\n",
    "        \n",
    "        # Handle different lengths\n",
    "        if len(ref) != len(pred):\n",
    "            print(f\"Length mismatch: Expected {len(ref)}, Got {len(pred)}\")\n",
    "            \n",
    "        # Show image file for reference\n",
    "        print(f\"Image file: {row['input_file']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0fdc2",
   "metadata": {},
   "source": [
    "**Good News!!**\n",
    "\n",
    "With preprocessing turned on, the performance on the 26 samples improved. CER improves from 13.85% to 3.85%, while WER improves from 50% to 15.38%. \n",
    "\n",
    "Let's see whether we can do more improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829a971",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "The sample size of 26 is relatively small. We could try to augment the small set by manipulating the original images, e.g., adding noise, changing brightness, etc. We do not apply manipulations like rotation, twist, re-coloring, etc. because the unseen captchas are expected to be similar in terms of numbers of characters, font, spacing, background and foreground color and texture, and skewness. \n",
    "\n",
    "**augment_captcha** is the function defined in **util.py** to generate new images based on the existing 26 captcha. New images would be written to <em>data/augmented</em> folder, while the labels are written to <em>data/output</em> folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a3b3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 26it [00:00, 198.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size increased from 26 to 104 images\n",
      "Augmented images saved to: ../data/augmented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "augmented_data = util.augment_captcha(preds_trocr_with_preprocessing_with_labels, captcha_solver.aug_dir, captcha_solver.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7f6743",
   "metadata": {},
   "source": [
    "Now apply the TrOCR model on those new images in the <em>data/augmented</em> folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b79d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 768,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.2\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TrOCR for inference\n",
      "Preprocessing turned on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsweng/.pyenv/versions/3.10.13/envs/captcha/lib/python3.10/site-packages/transformers/generation/utils.py:1667: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text 'EGYK4' saved to ../data/output/pred101.txt\n",
      "Generated text 'EGYK4' saved to ../data/output/pred102.txt\n",
      "Generated text 'EGYK4' saved to ../data/output/pred103.txt\n",
      "Generated text 'GRC35' saved to ../data/output/pred104.txt\n",
      "Generated text 'GRC35' saved to ../data/output/pred105.txt\n",
      "Generated text 'GRC35' saved to ../data/output/pred106.txt\n",
      "Generated text '605W1' saved to ../data/output/pred107.txt\n",
      "Generated text '605W1' saved to ../data/output/pred108.txt\n",
      "Generated text '605W1' saved to ../data/output/pred109.txt\n",
      "Generated text 'J627C' saved to ../data/output/pred110.txt\n",
      "Generated text 'J627C' saved to ../data/output/pred111.txt\n",
      "Generated text 'J627C' saved to ../data/output/pred112.txt\n",
      "Generated text 'VL I 2C' saved to ../data/output/pred113.txt\n",
      "Generated text 'VLI2C' saved to ../data/output/pred114.txt\n",
      "Generated text 'VLI2C' saved to ../data/output/pred115.txt\n",
      "Generated text '01RZQ' saved to ../data/output/pred116.txt\n",
      "Generated text '01RZQ' saved to ../data/output/pred117.txt\n",
      "Generated text '01RZQ' saved to ../data/output/pred118.txt\n",
      "Generated text 'OYTAD' saved to ../data/output/pred119.txt\n",
      "Generated text 'OYTAD' saved to ../data/output/pred120.txt\n",
      "Generated text 'OYTAD' saved to ../data/output/pred121.txt\n",
      "Generated text 'ZRMQU' saved to ../data/output/pred122.txt\n",
      "Generated text 'ZRMQU' saved to ../data/output/pred123.txt\n",
      "Generated text 'ZRMQU' saved to ../data/output/pred124.txt\n",
      "Generated text 'N9DQS' saved to ../data/output/pred125.txt\n",
      "Generated text 'N9DQS' saved to ../data/output/pred126.txt\n",
      "Generated text 'N9DQS' saved to ../data/output/pred127.txt\n",
      "Generated text 'ZGJ53' saved to ../data/output/pred128.txt\n",
      "Generated text 'ZGJ53' saved to ../data/output/pred129.txt\n",
      "Generated text 'ZGJ53' saved to ../data/output/pred130.txt\n",
      "Generated text 'G/MBA' saved to ../data/output/pred131.txt\n",
      "Generated text 'GZMBA' saved to ../data/output/pred132.txt\n",
      "Generated text 'GZMBA' saved to ../data/output/pred133.txt\n",
      "Generated text 'YMB1Q' saved to ../data/output/pred134.txt\n",
      "Generated text 'YMB1Q' saved to ../data/output/pred135.txt\n",
      "Generated text 'YMB10' saved to ../data/output/pred136.txt\n",
      "Generated text 'J14DM' saved to ../data/output/pred137.txt\n",
      "Generated text 'J14DM' saved to ../data/output/pred138.txt\n",
      "Generated text 'J14DM' saved to ../data/output/pred139.txt\n",
      "Generated text 'PQ9AE' saved to ../data/output/pred140.txt\n",
      "Generated text 'PQ9AE' saved to ../data/output/pred141.txt\n",
      "Generated text 'PQ9AE' saved to ../data/output/pred142.txt\n",
      "Generated text 'VWZDO' saved to ../data/output/pred143.txt\n",
      "Generated text 'VWZDO' saved to ../data/output/pred144.txt\n",
      "Generated text 'VWZDO' saved to ../data/output/pred145.txt\n",
      "Generated text 'WGST7' saved to ../data/output/pred146.txt\n",
      "Generated text 'WGST7' saved to ../data/output/pred147.txt\n",
      "Generated text 'WGST7' saved to ../data/output/pred148.txt\n",
      "Generated text 'XKMS2' saved to ../data/output/pred149.txt\n",
      "Generated text 'XKMS2' saved to ../data/output/pred150.txt\n",
      "Generated text 'XXX52' saved to ../data/output/pred151.txt\n",
      "Generated text '1D2KB' saved to ../data/output/pred152.txt\n",
      "Generated text '1D2KB' saved to ../data/output/pred153.txt\n",
      "Generated text '1D2KB' saved to ../data/output/pred154.txt\n",
      "Generated text '20BHQ' saved to ../data/output/pred155.txt\n",
      "Generated text '208HQ' saved to ../data/output/pred156.txt\n",
      "Generated text '20BHQ' saved to ../data/output/pred157.txt\n",
      "Generated text 'OAHOV' saved to ../data/output/pred158.txt\n",
      "Generated text 'OAHOV' saved to ../data/output/pred159.txt\n",
      "Generated text 'OAHOV' saved to ../data/output/pred160.txt\n",
      "Generated text '5I8VE' saved to ../data/output/pred161.txt\n",
      "Generated text '5I8VE' saved to ../data/output/pred162.txt\n",
      "Generated text '5I8VE' saved to ../data/output/pred163.txt\n",
      "Generated text 'Z97ME' saved to ../data/output/pred164.txt\n",
      "Generated text 'Z97ME' saved to ../data/output/pred165.txt\n",
      "Generated text 'Z97ME' saved to ../data/output/pred166.txt\n",
      "Generated text 'CL69V' saved to ../data/output/pred167.txt\n",
      "Generated text 'CL69V' saved to ../data/output/pred168.txt\n",
      "Generated text 'CL69V' saved to ../data/output/pred169.txt\n",
      "Generated text 'HCE91' saved to ../data/output/pred170.txt\n",
      "Generated text 'HCE91' saved to ../data/output/pred171.txt\n",
      "Generated text '#ICE91' saved to ../data/output/pred172.txt\n",
      "Generated text 'WELXV' saved to ../data/output/pred173.txt\n",
      "Generated text 'WELXV' saved to ../data/output/pred174.txt\n",
      "Generated text 'WELXV' saved to ../data/output/pred175.txt\n",
      "Generated text 'UHVFO' saved to ../data/output/pred176.txt\n",
      "Generated text 'UHVFO' saved to ../data/output/pred177.txt\n",
      "Generated text 'UNF0' saved to ../data/output/pred178.txt\n"
     ]
    }
   ],
   "source": [
    "captcha_solver = Captcha(device, \"../config.yaml\") # run again to reload the config.yaml\n",
    "\n",
    "preds_trocr_augmented_with_preprocessing = captcha_solver(mode = \"TrOCR\", im_path = \"../data/augmented\")  # let's use the augmented data only\n",
    "\n",
    "preds_trocr_augmented_with_preprocessing_with_labels = captcha_solver.add_gt_labels(preds_trocr_augmented_with_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f7844",
   "metadata": {},
   "source": [
    "### CER and WER calculation\n",
    "\n",
    "Time to evalaute the CER and WER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8482d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Character Error Rate (CER): 7.18%\n",
      "Overall Word Error Rate (WER): 26.92%\n",
      "\n",
      "Detailed Analysis:\n",
      "============================================================\n",
      "\n",
      "Sample 107:\n",
      "Expected: 6O5W1\n",
      "Predicted: 605W1\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'O', Got '0'\n",
      "Image file: ../data/augmented/input107.jpg\n",
      "\n",
      "Sample 108:\n",
      "Expected: 6O5W1\n",
      "Predicted: 605W1\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'O', Got '0'\n",
      "Image file: ../data/augmented/input108.jpg\n",
      "\n",
      "Sample 109:\n",
      "Expected: 6O5W1\n",
      "Predicted: 605W1\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'O', Got '0'\n",
      "Image file: ../data/augmented/input109.jpg\n",
      "\n",
      "Sample 113:\n",
      "Expected: VLI2C\n",
      "Predicted: VL I 2C\n",
      "CER: 40.00%\n",
      "WER: 300.00%\n",
      "Character differences:\n",
      "Position 2: Expected 'I', Got ' '\n",
      "Position 3: Expected '2', Got 'I'\n",
      "Position 4: Expected 'C', Got ' '\n",
      "Length mismatch: Expected 5, Got 7\n",
      "Image file: ../data/augmented/input113.jpg\n",
      "\n",
      "Sample 116:\n",
      "Expected: O1R7Q\n",
      "Predicted: 01RZQ\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'O', Got '0'\n",
      "Position 3: Expected '7', Got 'Z'\n",
      "Image file: ../data/augmented/input116.jpg\n",
      "\n",
      "Sample 117:\n",
      "Expected: O1R7Q\n",
      "Predicted: 01RZQ\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'O', Got '0'\n",
      "Position 3: Expected '7', Got 'Z'\n",
      "Image file: ../data/augmented/input117.jpg\n",
      "\n",
      "Sample 118:\n",
      "Expected: O1R7Q\n",
      "Predicted: 01RZQ\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'O', Got '0'\n",
      "Position 3: Expected '7', Got 'Z'\n",
      "Image file: ../data/augmented/input118.jpg\n",
      "\n",
      "Sample 128:\n",
      "Expected: ZGJS3\n",
      "Predicted: ZGJ53\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected 'S', Got '5'\n",
      "Image file: ../data/augmented/input128.jpg\n",
      "\n",
      "Sample 129:\n",
      "Expected: ZGJS3\n",
      "Predicted: ZGJ53\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected 'S', Got '5'\n",
      "Image file: ../data/augmented/input129.jpg\n",
      "\n",
      "Sample 130:\n",
      "Expected: ZGJS3\n",
      "Predicted: ZGJ53\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected 'S', Got '5'\n",
      "Image file: ../data/augmented/input130.jpg\n",
      "\n",
      "Sample 131:\n",
      "Expected: GZMBA\n",
      "Predicted: G/MBA\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'Z', Got '/'\n",
      "Image file: ../data/augmented/input131.jpg\n",
      "\n",
      "Sample 136:\n",
      "Expected: YMB1Q\n",
      "Predicted: YMB10\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 4: Expected 'Q', Got '0'\n",
      "Image file: ../data/augmented/input136.jpg\n",
      "\n",
      "Sample 151:\n",
      "Expected: XKMS2\n",
      "Predicted: XXX52\n",
      "CER: 60.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'K', Got 'X'\n",
      "Position 2: Expected 'M', Got 'X'\n",
      "Position 3: Expected 'S', Got '5'\n",
      "Image file: ../data/augmented/input151.jpg\n",
      "\n",
      "Sample 156:\n",
      "Expected: 20BHQ\n",
      "Predicted: 208HQ\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 2: Expected 'B', Got '8'\n",
      "Image file: ../data/augmented/input156.jpg\n",
      "\n",
      "Sample 158:\n",
      "Expected: OAH0V\n",
      "Predicted: OAHOV\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected '0', Got 'O'\n",
      "Image file: ../data/augmented/input158.jpg\n",
      "\n",
      "Sample 159:\n",
      "Expected: OAH0V\n",
      "Predicted: OAHOV\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected '0', Got 'O'\n",
      "Image file: ../data/augmented/input159.jpg\n",
      "\n",
      "Sample 160:\n",
      "Expected: OAH0V\n",
      "Predicted: OAHOV\n",
      "CER: 20.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 3: Expected '0', Got 'O'\n",
      "Image file: ../data/augmented/input160.jpg\n",
      "\n",
      "Sample 172:\n",
      "Expected: HCE91\n",
      "Predicted: #ICE91\n",
      "CER: 40.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 0: Expected 'H', Got '#'\n",
      "Position 1: Expected 'C', Got 'I'\n",
      "Position 2: Expected 'E', Got 'C'\n",
      "Position 3: Expected '9', Got 'E'\n",
      "Position 4: Expected '1', Got '9'\n",
      "Length mismatch: Expected 5, Got 6\n",
      "Image file: ../data/augmented/input172.jpg\n",
      "\n",
      "Sample 178:\n",
      "Expected: UHVFO\n",
      "Predicted: UNF0\n",
      "CER: 60.00%\n",
      "WER: 100.00%\n",
      "Character differences:\n",
      "Position 1: Expected 'H', Got 'N'\n",
      "Position 2: Expected 'V', Got 'F'\n",
      "Position 3: Expected 'F', Got '0'\n",
      "Length mismatch: Expected 5, Got 4\n",
      "Image file: ../data/augmented/input178.jpg\n"
     ]
    }
   ],
   "source": [
    "predictions = preds_trocr_augmented_with_preprocessing_with_labels['prediction'].tolist()\n",
    "references = preds_trocr_augmented_with_preprocessing_with_labels['ground_truth'].tolist()\n",
    "\n",
    "# Compute CER & WER\n",
    "cer_result = cer_metric.compute(predictions=predictions, references=references)\n",
    "wer_result = wer_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overall Character Error Rate (CER): {cer_result:.2%}\")\n",
    "print(f\"Overall Word Error Rate (WER): {wer_result:.2%}\")\n",
    "\n",
    "# Detailed analysis per sample\n",
    "print(\"\\nDetailed Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "# Iterate through DataFrame rows for detailed analysis\n",
    "for _, row in preds_trocr_augmented_with_preprocessing_with_labels.iterrows():\n",
    "    pred = row['prediction']\n",
    "    ref = row['ground_truth']\n",
    "    key = row['key']\n",
    "    \n",
    "    # Calculate metrics for this sample\n",
    "    sample_cer = cer_metric.compute(predictions=[pred], references=[ref])\n",
    "    sample_wer = wer_metric.compute(predictions=[pred], references=[ref])\n",
    "    \n",
    "    # Only show samples with errors\n",
    "    if sample_cer > 0 or sample_wer > 0:\n",
    "        print(f\"\\nSample {key}:\")\n",
    "        print(f\"Expected: {ref}\")\n",
    "        print(f\"Predicted: {pred}\")\n",
    "        print(f\"CER: {sample_cer:.2%}\")\n",
    "        print(f\"WER: {sample_wer:.2%}\")\n",
    "        \n",
    "        # Show character-by-character comparison\n",
    "        print(\"Character differences:\")\n",
    "        for j, (c1, c2) in enumerate(zip(ref, pred)):\n",
    "            if c1 != c2:\n",
    "                print(f\"Position {j}: Expected '{c1}', Got '{c2}'\")\n",
    "        \n",
    "        # Handle different lengths\n",
    "        if len(ref) != len(pred):\n",
    "            print(f\"Length mismatch: Expected {len(ref)}, Got {len(pred)}\")\n",
    "            \n",
    "        # Show image file for reference\n",
    "        print(f\"Image file: {row['input_file']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2f105",
   "metadata": {},
   "source": [
    "On the augmented data, the performance on the 78 samples improved. CER drops to 7.95% from 3.85%, while WER drops to 25.64% from 15.38%. \n",
    "\n",
    "Let's do a character-level analysis to see which characters are recognized wronly more often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d7eaa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of most common confusions:\n",
      "\n",
      "Character '0' was mistaken for:\n",
      "  - 'O': 3 times\n",
      "\n",
      "Character '1' was mistaken for:\n",
      "  - '9': 1 times\n",
      "\n",
      "Character '2' was mistaken for:\n",
      "  - 'I': 1 times\n",
      "\n",
      "Character '7' was mistaken for:\n",
      "  - 'Z': 3 times\n",
      "\n",
      "Character '9' was mistaken for:\n",
      "  - 'E': 1 times\n",
      "\n",
      "Character 'B' was mistaken for:\n",
      "  - '8': 1 times\n",
      "\n",
      "Character 'C' was mistaken for:\n",
      "  - ' ': 1 times\n",
      "  - 'I': 1 times\n",
      "\n",
      "Character 'E' was mistaken for:\n",
      "  - 'C': 1 times\n",
      "\n",
      "Character 'F' was mistaken for:\n",
      "  - '0': 1 times\n",
      "\n",
      "Character 'H' was mistaken for:\n",
      "  - '#': 1 times\n",
      "  - 'N': 1 times\n",
      "\n",
      "Character 'I' was mistaken for:\n",
      "  - ' ': 1 times\n",
      "\n",
      "Character 'K' was mistaken for:\n",
      "  - 'X': 1 times\n",
      "\n",
      "Character 'M' was mistaken for:\n",
      "  - 'X': 1 times\n",
      "\n",
      "Character 'O' was mistaken for:\n",
      "  - '0': 6 times\n",
      "\n",
      "Character 'Q' was mistaken for:\n",
      "  - '0': 1 times\n",
      "\n",
      "Character 'S' was mistaken for:\n",
      "  - '5': 4 times\n",
      "\n",
      "Character 'V' was mistaken for:\n",
      "  - 'F': 1 times\n",
      "\n",
      "Character 'Z' was mistaken for:\n",
      "  - '/': 1 times\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary to store confusion matrix data\n",
    "confusion_data = {}\n",
    "\n",
    "# Iterate through all predictions\n",
    "for _, row in preds_trocr_augmented_with_preprocessing_with_labels.iterrows():\n",
    "    pred = row['prediction']\n",
    "    ref = row['ground_truth']\n",
    "    \n",
    "    # Compare characters\n",
    "    for expected, predicted in zip(ref, pred):\n",
    "        if expected != predicted:\n",
    "            # Initialize nested dictionary if needed\n",
    "            if expected not in confusion_data:\n",
    "                confusion_data[expected] = {}\n",
    "            if predicted not in confusion_data[expected]:\n",
    "                confusion_data[expected][predicted] = 0\n",
    "            \n",
    "            # Increment count\n",
    "            confusion_data[expected][predicted] += 1\n",
    "\n",
    "# Get all unique characters (both expected and predicted)\n",
    "all_chars = sorted(set(\n",
    "    list(confusion_data.keys()) + \n",
    "    [char for d in confusion_data.values() for char in d.keys()]\n",
    "))\n",
    "\n",
    "# Create confusion matrix\n",
    "matrix_size = len(all_chars)\n",
    "confusion_matrix = np.zeros((matrix_size, matrix_size))\n",
    "\n",
    "# Fill the confusion matrix\n",
    "for i, expected in enumerate(all_chars):\n",
    "    if expected in confusion_data:\n",
    "        for j, predicted in enumerate(all_chars):\n",
    "            if predicted in confusion_data[expected]:\n",
    "                confusion_matrix[i, j] = confusion_data[expected][predicted]\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(confusion_matrix, \n",
    "            xticklabels=all_chars,\n",
    "            yticklabels=all_chars,\n",
    "            annot=True,  # Show numbers in cells\n",
    "            fmt='g',     # Format as integer\n",
    "            cmap='YlOrRd',  # Yellow to Orange to Red color scheme\n",
    "            square=True)    # Make cells square\n",
    "\n",
    "plt.title('Character Recognition Confusion Matrix')\n",
    "plt.xlabel('Predicted Character')\n",
    "plt.ylabel('Expected Character')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSummary of most common confusions:\")\n",
    "for expected in all_chars:\n",
    "    if expected in confusion_data and confusion_data[expected]:\n",
    "        print(f\"\\nCharacter '{expected}' was mistaken for:\")\n",
    "        sorted_mistakes = sorted(confusion_data[expected].items(), \n",
    "                               key=lambda x: x[1], \n",
    "                               reverse=True)\n",
    "        for predicted, count in sorted_mistakes:\n",
    "            print(f\"  - '{predicted}': {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251f6a1",
   "metadata": {},
   "source": [
    "The heatmap above shows that digit \"0\" and alphabet \"O\" confused the model the most. This pair is known to be challenging for CV models, and visually difficult to diffentiate even for human eyes. Other difficult pairs here include \"S\" and \"5\", \"Z\" and \"2\". \n",
    "\n",
    "We could try to fine tune a base model with those augmented data. Due to time constraint, the fine-tuning was not run to complete. Below is the working code used for fine-tuning with torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2deba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 104\n",
      "Training samples: 83\n",
      "Test samples: 21\n",
      "\n",
      "Training set distribution:\n",
      "Original images: 21\n",
      "Augmented images: 62\n",
      "\n",
      "Test set distribution:\n",
      "Original images: 5\n",
      "Augmented images: 16\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# split data into train and test\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the DataFrame into train and test sets\n",
    "train_df, test_df = train_test_split(\n",
    "    augmented_data,\n",
    "    test_size=0.2,  # 20% for test set\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(augmented_data)}\")\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# Print sample distribution\n",
    "def print_distribution(df, name):\n",
    "    original = len(df[~df['augmented']])\n",
    "    augmented = len(df[df['augmented']])\n",
    "    print(f\"\\n{name} set distribution:\")\n",
    "    print(f\"Original images: {original}\")\n",
    "    print(f\"Augmented images: {augmented}\")\n",
    "    \n",
    "print_distribution(train_df, \"Training\")\n",
    "print_distribution(test_df, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f380c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 83\n",
      "Test samples: 21\n",
      "\n",
      "Sample data:\n",
      "Input shape: torch.Size([3, 384, 384])\n",
      "Label shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, dataframe, processor, max_target_length=128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: DataFrame containing image paths and labels\n",
    "            processor: TrOCR processor for image and text processing\n",
    "            max_target_length: Maximum length for text encoding padding\n",
    "        \"\"\"\n",
    "        self.data = dataframe\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get row from DataFrame\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        image = Image.open(row['input_file']).convert(\"RGB\")\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        \n",
    "        # Encode the text label\n",
    "        labels = self.processor.tokenizer(\n",
    "            row['ground_truth'],\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_target_length\n",
    "        ).input_ids\n",
    "        \n",
    "        # Replace padding tokens with -100 for loss calculation\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "        \n",
    "        # Return processed image and encoded labels\n",
    "        encoding = {\n",
    "            \"pixel_values\": pixel_values.squeeze(),\n",
    "            \"labels\": torch.tensor(labels)\n",
    "        }\n",
    "        return encoding\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset = CaptchaDataset(train_df, captcha_solver.processor)\n",
    "test_dataset = CaptchaDataset(test_df, captcha_solver.processor)\n",
    "\n",
    "# Verify the dataset\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Test a sample\n",
    "sample = train_dataset[0]\n",
    "print(\"\\nSample data:\")\n",
    "print(f\"Input shape: {sample['pixel_values'].shape}\")\n",
    "print(f\"Label shape: {sample['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "491a44bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample batch:\n",
      "Pixel values shape: torch.Size([3, 384, 384])\n",
      "Labels shape: torch.Size([128])\n",
      "Original text: ZGJS3\n",
      "Encoded labels: [0, 1301, 534, 37337, 246, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "ZGJS3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test a single batch\n",
    "sample = train_dataset[0]\n",
    "\n",
    "print(\"\\nSample batch:\")\n",
    "print(f\"Pixel values shape: {sample['pixel_values'].shape}\")\n",
    "print(f\"Labels shape: {sample['labels'].shape}\")\n",
    "print(f\"Original text: {train_df['ground_truth'].iloc[0]}\")\n",
    "print(f\"Encoded labels: {sample['labels'].tolist()}\")\n",
    "labels = sample['labels']\n",
    "labels[labels == -100] = captcha_solver.processor.tokenizer.pad_token_id\n",
    "label_str = captcha_solver.processor.decode(labels, skip_special_tokens=True)\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "594e3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# create dataloader\n",
    "'''\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5611d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 768,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.2\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderModel(\n",
       "  (encoder): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (pooler): ViTPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TrOCRForCausalLM(\n",
       "    (model): TrOCRDecoderWrapper(\n",
       "      (decoder): TrOCRDecoder(\n",
       "        (embed_tokens): TrOCRScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): TrOCRLearnedPositionalEmbedding(514, 1024)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_projection): Linear(in_features=1024, out_features=50265, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# prep for finetuning\n",
    "'''\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\") # microsoft/trocr-base-stage1 has not been fine-tuned on any dataset. \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80538ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# make some configurations \n",
    "'''\n",
    "\n",
    "# set special tokens used for creating the decoder_input_ids from the labels\n",
    "model.config.decoder_start_token_id = captcha_solver.processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = captcha_solver.processor.tokenizer.pad_token_id\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# set beam search parameters\n",
    "model.config.eos_token_id = captcha_solver.processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 64\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa91c25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac29bee78c744bfbd173cad6dfc458b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 12.558970737457276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7780b01bf7624025b93e759c5dde7f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1: 7.4865728378295895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03a894dcc594d2fbf542238ae5ad534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/captcha/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/captcha/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/captcha/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "# fine tuning\n",
    "'''\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(100):  \n",
    "   # train\n",
    "   model.train()\n",
    "   train_loss = 0.0\n",
    "   for batch in tqdm(train_dataloader):\n",
    "      # get the inputs\n",
    "      for k,v in batch.items():\n",
    "        batch[k] = v.to(device)\n",
    "\n",
    "      outputs = model(**batch)\n",
    "      loss = outputs.loss\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      train_loss += loss.item()\n",
    "\n",
    "   print(f\"Loss after epoch {epoch}:\", train_loss/len(train_dataloader))\n",
    "    \n",
    "   \n",
    "\n",
    "model.save_pretrained(\"../model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captcha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
